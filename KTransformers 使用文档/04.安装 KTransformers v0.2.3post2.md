# 安装 KTransformers v0.2.3post2

## 简介

KTransformers v0.2.3post2 版本：
* 支持 Prefix Caching（前缀缓存）

GitHub 项目地址：https://github.com/kvcache-ai/ktransformers

## 使用虚拟环境

1. 创建一个 Python=3.12 的虚拟环境：
```
conda create --name ktransformers python=3.12 -y
```

2. 使用虚拟环境：
```
conda activate ktransformers
```

## 安装依赖

1. 安装 C++ 运行时依赖库：
```
conda install -c conda-forge libstdcxx-ng -y
```

2. 安装 PyTorch：
```
pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu124
```

如果以上命令下载速度太慢，可以使用下载工具直接下载软件包：
```
cd /app/

wget https://download.pytorch.org/whl/cu124/torch-2.4.1+cu124-cp312-cp312-linux_x86_64.whl
wget https://download.pytorch.org/whl/cu124/torchvision-0.19.1+cu124-cp312-cp312-linux_x86_64.whl
wget https://download.pytorch.org/whl/cu124/torchaudio-2.4.1+cu124-cp312-cp312-linux_x86_64.whl
```

手动安装 PyTorch：
```
pip install torch-2.4.1+cu124-cp312-cp312-linux_x86_64.whl
pip install torchvision-0.19.1+cu124-cp312-cp312-linux_x86_64.whl
pip install torchaudio-2.4.1+cu124-cp312-cp312-linux_x86_64.whl
```

3. 安装 FlashAttention：
```
pip install flash-attn --no-build-isolation
```

4. 安装 FlashInfer：
```
pip install flashinfer-python --no-build-isolation
```

5. 安装 OpenAI：
```
pip install openai
```

## 安装 KTransformers

KTransformers 提供两种安装方式：
* 使用官方构建的软件包进行安装（推荐）
* 构建源代码进行安装

建议先查找官方是否已提供与系统兼容的软件包。如果有匹配的软件包，直接使用软件包进行安装；如果没有匹配的软件包，再构建源代码进行安装。

### 软件包安装

1. 访问软件包发布页面：https://github.com/kvcache-ai/ktransformers/releases

2. 找到版本号为“v0.2.3post2”的发布条目，并根据 Python 版本、PyTorch 版本以及 CPU 支持的指令集，选择匹配的软件包。

3. 查看 Python 版本号：
```
python -V
```

出现内容：
```
Python 3.12.9
```

4. 查看 PyTorch 和 CUDA 版本号：
```
python -c "import torch; print(torch.__version__, torch.version.cuda)"
```

出现内容：
```
2.4.1+cu124 12.4
```

5. 查看 CPU 支持的指令集：
```
cat /proc/cpuinfo | grep -i 'flags'
```

出现内容：
```
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr rdpru wbnoinvd amd_ppin arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif v_spec_ctrl umip rdpid overflow_recov succor smca sev sev_es
```

6. 根据以上信息，需要选择“ktransformers-0.2.3.post2+torch24avx2-cp312-cp312-linux_x86_64.whl”，右击复制链接。

7. 下载软件包： 
```
cd /app/

wget https://github.com/kvcache-ai/ktransformers/releases/download/v0.2.3post2/ktransformers-0.2.3.post2+torch24avx2-cp312-cp312-linux_x86_64.whl
```

8. 安装软件包：
```
pip install ktransformers-0.2.3.post2+torch24avx2-cp312-cp312-linux_x86_64.whl
```

### 构建源代码安装

1. 更新系统软件包：
```
sudo apt update && sudo apt upgrade -y
```

2. 安装系统构建工具：
```
sudo apt install -y build-essential cmake ninja-build patchelf
```

3. 安装 Python 构建工具：
```
pip install packaging ninja cpufeature numpy
```

4. 下载源代码：
```
cd /app/

git clone https://github.com/kvcache-ai/ktransformers.git --recursive --branch v0.2.3post2 --depth 1
```

5. 运行安装脚本：
```
cd /app/ktransformers/

bash ./install.sh
```

等待安装完成后，出现内容：
```
……
……
……
Successfully built ktransformers
Installing collected packages: ktransformers
Successfully installed ktransformers-0.2.3.post2+torch24avx2
Installation completed successfully
```

## 查看已安装的 Python 包及其版本

1. 查看已安装的 Python 包及其版本：
```
pip list
```

出现内容：
```
flash_attn               2.7.4.post1
flashinfer-python        0.2.5
ktransformers            0.2.3.post2+torch24avx2
openai                   1.78.0
torch                    2.4.1+cu124
transformers             4.43.2
```

## 配置环境变量

1. 编辑环境变量配置文件：
```
sudo vim /etc/profile
```

2. 在文件末尾添加以下内容：
```
export TORCH_CUDA_ARCH_LIST=8.9
```

这里的值是指 GPU 的计算架构版本，比如“8.9”对应“sm_89”。你需要根据自己显卡的型号来填写合适的版本号。

这里列举了常见的显卡型号和架构版本之间的对应关系：
| 显卡型号     | 架构版本     | TORCH_CUDA_ARCH_LIST  |
| ----------- | ----------- | --------------------- |
| RTX 4090    | sm_89       | 8.9                   |
| RTX 3090    | sm_86       | 8.6                   |
| RTX 2080 Ti | sm_75       | 7.5                   |
| A100        | sm_80       | 8.0                   |

3. 使环境变量配置立即生效：
```
source /etc/profile
```

## 卸载 KTransformers

1. 卸载 KTransformers：
```
pip uninstall ktransformers
```

