# 报错信息

## 问题 1

### 问题描述

启动阶段报错：
```
KeyError: 'Key blk.10.attn_q_a.weight not found in Safetensor files'
```

### 问题分析

权重文件有问题，缺失或者损坏。

### 解决办法

重新下载权重文件。

## 问题 2

### 问题描述

启动阶段报错：
```
RuntimeError: The expanded size of the tensor (16384) must match the existing size (13246) at non-singleton dimension 0.  Target sizes: [16384, 256].  Tensor sizes: [13246, 256]
```

### 问题分析

存放权重文件的目录里面有其他文件（比如以 `.` 开头的隐藏文件）。

### 解决办法

删除除了权重文件以外的其他文件。

## 问题 3

### 问题描述

运行阶段报错：
```
max_new_tokens is less than 0
```

### 问题分析

“max_new_tokens”是模型可以生成的最大 token 数量。在当前会话中，模型之前生成的 token 数量与即将生成的 token 数量之和不能超过这个最大值，一旦超过这个值，生成过程会被强制停止。

### 解决办法

减少发送的上下文数（模型之前生成的 token ），或者增大“max_new_tokens”的值。

## 问题 4

### 问题描述

运行阶段报错：
```
input_ids_length 8207 > cache_lens 8192
```

### 问题分析

“input_ids_length”是用户输入的 token 数量，“cache_lens”是模型可以缓存的最大 token 数量。“input_ids_length”的值不能超过“cache_lens”的值。

### 解决办法

减少发送的 token 数量，或者增大“cache_lens”的值。

## 问题 5

### 问题描述

运行阶段报错：
```
seq_length bigger than cache_lens, killed
```

### 问题分析

“seq_length”是前端程序输入的 token 数量，“cache_lens”是模型可以缓存的最大 token 数量。“seq_length”的值不能超过“cache_lens”的值。

### 解决办法

减少发送的 token 数量，或者增大“cache_lens”的值。

## 问题 6

### 问题描述

运行阶段报错：
```
Traceback (most recent call last):
  File "/app/anaconda3/envs/ktransformers/bin/ktransformers", line 5, in <module>
    from ktransformers.server.main import main
  File "/app/anaconda3/envs/ktransformers/lib/python3.12/site-packages/ktransformers/server/main.py", line 11, in <module>
    from ktransformers.server.args import ArgumentParser
  File "/app/anaconda3/envs/ktransformers/lib/python3.12/site-packages/ktransformers/server/args.py", line 3, in <module>
    from ktransformers.util.utils import get_free_ports
  File "/app/anaconda3/envs/ktransformers/lib/python3.12/site-packages/ktransformers/util/utils.py", line 17, in <module>
    from ktransformers.models.custom_cache import StaticCache
  File "/app/anaconda3/envs/ktransformers/lib/python3.12/site-packages/ktransformers/models/custom_cache.py", line 15, in <module>
    from ktransformers.server.balance_serve.settings import sched_ext
  File "/app/anaconda3/envs/ktransformers/lib/python3.12/site-packages/ktransformers/server/balance_serve/settings.py", line 13, in <module>
    import sched_ext
ImportError: /app/ktransformers/build/lib.linux-x86_64-cpython-312/libcache_entry.so: undefined symbol: _ZN21PageAlignedMemoryPool5debugB5cxx11Ev
```

### 问题分析

报错内容显示，在加载的 `libcache_entry.so` 动态库文件中，存在未解析的符号。

这是因为在构建 CUDA 插件时使用的 C++ ABI 设置与当前 PyTorch 环境的 C++ ABI 设置不一致，导致动态库文件无法正确加载。

### 查看构建日志

查看 KTransformers 的构建日志，找到构建 `libcache_entry.so` 动态库文件的日志：
```
  cd /app/ktransformers/csrc/balance_serve/build/kvc2/src && /usr/bin/g++-11 -DUSE_C10D_GLOO -DUSE_C10D_NCCL -DUSE_DISTRIBUTED -DUSE_RPC -DUSE_TENSORPIPE -D_GLIBCXX_USE_CXX11_ABI=0 -Dcache_entry_EXPORTS -I/app/ktransformers/csrc/balance_serve/../../third_party -I/app/ktransformers/csrc/balance_serve/kvc2/../../third_party -I/app/ktransformers/csrc/balance_serve/../../third_party/asyncio/include -I/app/ktransformers/csrc/balance_serve/build/third_party/prometheus-cpp/core/include -I/app/ktransformers/csrc/balance_serve/build/third_party/prometheus-cpp/pull/include -I/app/ktransformers/csrc/balance_serve/../../third_party/prometheus-cpp/core/include -I/app/ktransformers/csrc/balance_serve/../../third_party/prometheus-cpp/pull/include -I/app/ktransformers/csrc/balance_serve/../../third_party/spdlog/include -I/app/ktransformers/third_party/xxHash/cmake_unofficial/.. -I/app/ktransformers/csrc/balance_serve/../../third_party/nlohmann/single_include -isystem /app/anaconda3/envs/ktransformers/lib/python3.12/site-packages/torch/include -isystem /app/anaconda3/envs/ktransformers/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda/include -O3 -march=native -Wall -Wextra -fPIC -g -fPIC -D_GLIBCXX_USE_CXX11_ABI=1 -std=gnu++20 -MD -MT kvc2/src/CMakeFiles/cache_entry.dir/cache_entry.cpp.o -MF CMakeFiles/cache_entry.dir/cache_entry.cpp.o.d -o CMakeFiles/cache_entry.dir/cache_entry.cpp.o -c /app/ktransformers/csrc/balance_serve/kvc2/src/cache_entry.cpp
```

日志内容显示，构建命令中有两个“D_GLIBCXX_USE_CXX11_ABI”参数，前一个参数的值为“0”，后一个参数的值为“1”。

执行以下命令获取 PyTorch 环境的 C++ ABI 设置：
```
python -c "import torch; print(torch._C._GLIBCXX_USE_CXX11_ABI)"
```

出现内容：
```
True
```

输出说明：
* True：表示 PyTorch 环境使用的是 C++11 ABI。
* False：表示 PyTorch 环境使用的是较旧的 ABI。

对应到构建命令中“D_GLIBCXX_USE_CXX11_ABI”参数的值：
* True：表示“D_GLIBCXX_USE_CXX11_ABI”参数的值为“1”。
* False：表示“D_GLIBCXX_USE_CXX11_ABI”参数的值为“0”。

因此后一个“D_GLIBCXX_USE_CXX11_ABI”参数的值（为“1”）应该是构建脚本从 PyTorch 环境动态获取的。

### 检查构建脚本

现在来找出前一个“D_GLIBCXX_USE_CXX11_ABI”参数的值（为“0”）是从哪里获取的，检查 KTransformers 的构建脚本，找到下面两个文件：
```
/app/ktransformers/csrc/balance_serve/CMakeLists.txt
/app/ktransformers/csrc/balance_serve/kvc2/CMakeLists.txt
```

这两个文件都包含这行代码：
```
add_definitions(-D_GLIBCXX_USE_CXX11_ABI=0)
```

这行代码作用是给构建命令添加一个“D_GLIBCXX_USE_CXX11_ABI=0”的参数。

这就是构建命令中会出现两个“D_GLIBCXX_USE_CXX11_ABI”参数的原因，并且两者的值不一致，导致构建出来的 `libcache_entry.so` 动态库文件与 PyTorch 环境不兼容，最终导致在加载 `libcache_entry.so` 动态库文件时出现错误。

### 解决办法

注释这两个文件中的相关代码：
```
#add_definitions(-D_GLIBCXX_USE_CXX11_ABI=0)
```

然后重新执行构建脚本：
```
env USE_BALANCE_SERVE=1 bash ./install.sh
```

